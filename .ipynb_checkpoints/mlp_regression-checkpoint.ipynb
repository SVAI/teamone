{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.13.1\n",
      "Python 3.7.1 (v3.7.1:260ec2c36a, Oct 20 2018, 03:13:28) \n",
      "[Clang 6.0 (clang-600.0.57)]\n"
     ]
    }
   ],
   "source": [
    "# import libraries, set random seed for reproducibility\n",
    "# recommended TensorFlow version >= 1.12.0\n",
    "# recommended Python version >= 3.5\n",
    "\n",
    "# if libraries are missing:\n",
    "# !pip install h5py\n",
    "# !pip install matplotlib\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install seaborn\n",
    "# !pip install sklearn\n",
    "# !pip install tensorflow\n",
    "# !pip install tqdm\n",
    "\n",
    "import os\n",
    "import platform\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "print(\"TensorFlow\", tf.__version__)\n",
    "print(\"Python\", platform.sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ###\n",
    "nsamples, nx, ny = X.shape\n",
    "X = X.reshape((nsamples,nx*ny))\n",
    "\n",
    "num_fts = ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_values = ###\n",
    "ic50_values = ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to scale values???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "# Split the data into training and testing sets\n",
    "train_ft_auc, test_ft_auc, train_lab_auc, test_lab_auc = train_test_split(X, auc_values, test_size = 0.3, random_state = 0)\n",
    "train_ft_ic50, test_ft_ic50, train_lab_ic50, test_lab_ic50 = train_test_split(X, ic50_values, test_size = 0.3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from here\n",
    "# https://medium.com/datadriveninvestor/building-neural-network-using-keras-for-regression-ceee5a9eadff\n",
    "# https://datascienceplus.com/keras-regression-based-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regressor():\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=100, input_dim=num_fts, kernel_initializer='normal', activation='relu'))\n",
    "    regressor.add(Dense(units=50, activation = 'relu'))\n",
    "    regressor.add(Dense(units=38, activation = 'linear'))\n",
    "    regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae', 'mse','accuracy'])\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = KerasRegressor(build_fn=build_regressor, batch_size=20,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_pred)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = results.history['val_loss']\n",
    "loss = results.history['loss']\n",
    "print(regressor.summary())\n",
    "# let's plot the performance curve\n",
    "plt.figure()\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.plot(loss, label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shapley additive feature attribution\n",
    "# code from here: https://towardsdatascience.com/interpretability-of-deep-learning-models-9f52e54d72ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do interpretability\n",
    "import shap\n",
    "\n",
    "#initialize js methods for visualization\n",
    "shap.initjs()\n",
    "\n",
    "# create an instance of the DeepSHAP which is called DeepExplainer\n",
    "explainer_shap = shap.DeepExplainer(model=regressor,\n",
    "                                 data=X_train)\n",
    "\n",
    "# Fit the explainer on a subset of the data (you can try all but then gets slower)\n",
    "shap_values = explainer_shap.shap_values(X=X_train.values[:500],\n",
    "                                      ranked_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's inspect some individual explanations inferred by DeepSHAP\n",
    "shap.force_plot(explainer_shap.expected_value,\n",
    "                shap_values[0][0],\n",
    "                feature_names=X_train.columns)\n",
    "\n",
    "shap.force_plot(explainer_shap.expected_value,\n",
    "                shap_values[0][0][1],\n",
    "                X_train.values[:500][0],\n",
    "                feature_names=X_train.columns,)\n",
    "\n",
    "shap.force_plot(explainer_shap.expected_value,\n",
    "                shap_values[0][0][1],\n",
    "                X_train.values[:500][0],\n",
    "                feature_names=X_train.columns,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the output value and base value\n",
    "record = 1 # this is just to pick one record in the dataset \n",
    "base_value = explainer_2.expected_value\n",
    "output= base_value + np.sum(shap_values[0][0][record])\n",
    "print('base value: ',base_value)\n",
    "print('output value: ',output)\n",
    "\n",
    "#sanity check that the ouput value is equal to the actual prediction\n",
    "print(np.round(output,decimals=1) == np.round(model.predict(X_train.values)[record],decimals=1))\n",
    "\n",
    "\n",
    "# to get the shape values or each feature\n",
    "shap_df = pd.DataFrame(list(dict(zip(X_train.columns.values,base_value)).items()),\n",
    "             columns=['features','shapvals']).sort_values(by='shapvals', ascending=True)\n",
    "print(shap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ovearall mean contribution of each feature variable\n",
    "shap.summary_plot(shap_values[0], X_train.values[:500], feature_names=X_train.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
